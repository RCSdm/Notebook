## LLM 微调方法

大模型微调是提升预训练大模型在特定任务或领域表现的重要手段。微调方法可以分为全量微调（Full Fine Tuning, FFT）和参数高效微调（Parameter-Efficient Fine Tuning, PEFT）。

### 全量微调（FFT）

全量微调是对大模型的所有参数进行训练。这种方法虽然可以显著提升模型在特定任务上的表现，但也存在一些问题：

  * 训练成本高：微调的参数量与预训练时相同，导致训练成本非常高。
  * 灾难性遗忘：特定领域的数据微调可能会导致模型在其他领域的表现变差。

### 参数高效微调（PEFT）

参数高效微调旨在解决全量微调的高成本和灾难性遗忘问题。PEFT 方法主要包括以下几种：

  * **Adapter Tuning** ：通过在每个 Transformer 层中插入两个串行的 Adapter 模块来实现微调。Adapter 模块由两个前馈子层组成，分别负责将特征维度投影到更小的维度并再投影回原始维度。这种方法只需增加少量参数即可达到接近全量微调的效果。
  * **Prefix Tuning** ：在 Transformer 的 Encoder 和 Decoder 网络中添加特定的前缀，优化前缀参数而不改变基座模型。这种方法在表格到文本任务上表现优于全量微调。
  * **P - Tuning** ：在输入层加入可微的虚拟 Token，通过反向传播和梯度下降更新参数。这种方法在自然语言理解任务中表现优异。
  * **Prompt Tuning** ：在输入序列前增加特定长度的特殊 Token，训练少量参数的小模型。这种方法在大模型上效果接近全量微调。
  * **LoRA** ：通过在每个 self - attention 层中加入低秩矩阵来实现微调，显著减少了可训练参数数量。这种方法在多个数据集上表现与全量微调相近。
  * **AdaLoRA** ：基于权重矩阵的重要性自适应调整不同模块的秩，进一步提升了 LoRA 的性能。

### 结论

微调的最终目的是在可控成本的前提下，尽可能提升大模型在特定领域的能力。不同的微调方法各有优缺点，选择合适的方法可以根据具体任务和资源情况进行调整。