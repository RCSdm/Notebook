## LI-GS: 结合激光雷达的高斯散点法用于精确的大规模重建

**摘要**：大规模 3D 重建在机器人领域至关重要，3D 高斯散点法 (3DGS) 在实现精确物体级重建方面的潜力已得到证明。然而，在户外和无界场景中确保几何精度仍然是一个重大挑战。本研究介绍了 LI-GS，这是一种结合激光雷达和高斯散点法的重建系统，可增强大规模场景的几何精度。研究使用 2D 高斯 surfel 作为地图表示，以改善表面配准。此外，提出了一种新的建模方法，将激光雷达点云转换为平面约束的多模态高斯混合模型 (GMM)。在初始化和优化阶段都使用这些 GMM，以确保在整个场景中提供充分且持续的监督，同时降低过拟合的风险。此外，在网格提取中也使用了 GMM，以消除伪影并提高整体几何质量。实验表明，该方法在大规模 3D 重建中优于现有方法，与基于激光雷达的方法和基于高斯的方法相比，精度分别提高了 52.6% 和 68.7%。

### 一、引言
在大规模户外环境中的导航对于自动驾驶、工业检查和具身 AI 等各种机器人应用至关重要。重建环境的精确且密集的 3D 地图对于实现这些任务具有重要意义。激光雷达 - 视觉融合是一种将激光雷达提供的几何信息与相机捕获的纹理信息相结合的 3D 重建技术。最近，3D 高斯散点法 (3DGS) 因其显著减少的训练时间和实现实时渲染的能力而受到广泛关注。这些优势使 3DGS 成为一种有希望的地图表示方法。然而，在稀疏视图、无界和大规模场景中实现几何精确重建仍然是一个挑战。

### 二、相关工作
#### (一) 大规模 3D 重建
与中显示的显式 3D 表示相比，一些研究采用神经隐式表示进行基于激光雷达的户外 3D 重建。这些方法使用多层感知机 (MLP) 来封装整个场景并取得满意的结果。此外，一些隐式方法采用激光雷达 - 视觉融合方法进行大规模场景重建。与神经隐式表示不同，3D 高斯散点法 (3DGS) 利用一组具有可学习属性的高斯来显式表示外观和几何形状，从而实现实时渲染。

#### (二) 使用高斯进行几何精确重建
提出了许多基于高斯的方法来提高 3D 重建的几何精度。2DGS 和高斯 surfel 提出将高斯椭球展平为 surfel，并引入法线 - 深度一致性正则化。除仅关注正则化外，Trim3DGS 提出了一种基于贡献的修剪策略，以消除不准确的高斯。GOF 使用基于光线追踪的体渲染来直接提取几何形状。在网格提取方面，高斯 surfel 涉及使用高斯构建占用图，并移除未占用体素内的采样点。

### 三、预备知识
2DGS 使用一组平坦的高斯 surfel 来建模场景，使其能够更好地与薄表面对齐。surfel 的基本属性包括中心点、半径、两个对应的归一化正交向量、法向量、不透明度和视图依赖的外观。高斯 surfel 定义了一个局部 2D 切空间。将该空间中的点转换为世界空间后，可以通过 2D 到 2D 的映射将其投影到图像空间。

### 四、方法论
#### (一) 预处理
该系统处理激光雷达扫描和 RGB 图像作为输入，并进行预处理以提高数据精度。首先，使用 SLICT 估计激光雷达扫描的初始位姿。然后，使用 M-detector 移除扫描中的动态物体，随后通过 HBA 提高全球点云的精度。对于输入图像，先前的工作提供了准确的初始图像位姿。这些位姿进一步使用 Colmap-PCD 进行细化。预处理步骤生成了精确的全球点云和一致的图像位姿。

#### (二) 初始化
研究提出了一种从大规模彩色点云生成多模态高斯混合模型 (GMM) 的方法，并利用空间哈希高效维护 GMM。首先，遍历图像并投影全球点云，生成一系列彩色点云帧。对于第一帧，执行体素化，然后在每个体素内使用 RANSAC 提取平面。将位于同一平面上的点集表示为 \( P = \{z_i | z_i = [p_i, g_i]^T, p_i \in \mathbb{R}^3, g_i \in [0, 1] \} \)，其中 \( p_i \) 表示世界空间中的位置，\( g_i \) 表示基于 RGB 值计算的灰度。这些点的协方差矩阵的特征值和特征向量用于构建局部 4D GMM。

#### (三) 优化
尽管在初始化阶段引入了激光雷达，但仅使用光度损失进行优化时，3DGS 和 2DGS 在稀疏视图场景中仍会产生噪声重建。为解决此问题，研究提出了一种全面的归一化方法和创新的几何感知密度控制方法。

#### (四) 网格提取
高斯 surfel 构建占用图并移除未占用体素内的采样点，以消除深度不连续处的伪影。然而，在无界场景中，大网格可能导致过多的点移除，而小网格则会影响计算效率。为了解决这个问题，研究将 GMM 应用于网格提取。首先构建体素图并计算占用率，然后移除未占用体素内的样本。接下来，根据加权距离 \( d(p) \) 抛弃远离物体表面的样本，最后使用带筛选的泊松方法提取网格。

### 五、实验
#### (一) 实验设置
研究开发了一个数据采集平台，包括两个 HESAI XT32 激光雷达传感器、一个 Insta360 ONE RS 相机和一个 Alubi LPMS-IG1 IMU。在室内外环境中收集了 6 个场景的数据，涵盖了无界和稀疏视图区域。使用单一 RTX-4090 GPU 进行所有实验，并采用表 2 中的参数设置。

#### (二) 比较研究
研究将提出的方法与仅使用激光雷达的四种映射方法以及九种最先进的基于高斯的曲面重建方法进行了比较。结果表明，该方法在所有指标上均优于基线方法。

#### (三) 消融研究
1. **初始化**：比较了三种初始化方法：Colmap-PCD 生成的 SfM 点、彩色激光雷达点云和基于 GMM 的初始化方法。结果表明，基于 GMM 的初始化方法在几何质量方面表现最佳。
2. **优化**：评估了使用和不使用 GMM 归一化的方法的几何质量，结果表明使用 GMM 归一化的方法在几何质量方面表现更好。
3. **网格提取**：比较了三种网格提取方法，结果表明该方法在准确性和完整性之间取得了良好的平衡。

### 六、结论
论文介绍了一种结合激光雷达与高斯散点法的大规模场景重建系统 LI-GS，并提出了一种具有平面约束的增量多模态建模方法来生成高斯混合模型 (GMM)。实验验证了 LI-GS 在 3D 重建中的卓越性能，未来的工作将涉及将该方法应用于同步定位与地图构建 (SLAM)。

## RISED: 使用图像进行精确高效的 RGB 彩色映射选择和点云致密化

**摘要**：近期，彩色点云在机器人领域的价值凸显。传统多传感器融合的 SLAM 系统利用所有可用图像进行彩色化，导致彩色点云模糊。尽管相机位姿精确，提升彩色点云质量仍是难题。本研究提出 RISED，从投影精度和分布均匀性两方面优化彩色点云。通过分析相机位姿对彩色化的影响，选择最佳视角以减少误差；运用动态高斯混合模型（GMM）进行点云致密化，消除激光雷达扫描痕迹。此外，引入新评估方法，全面考量彩色点云的精度与效率。实验表明，RISED 在投影精度、几何精度及映射效率上分别提升 55.2%、63.1% 和 30.8%，优于传统方法。

### 一、引言
彩色点云在机器人自主导航、感知和规划等任务中越发重要，也被用于神经辐射场（NeRF）和高斯散点法的初始化阶段。激光雷达 - 视觉融合的 SLAM 技术因激光雷达的精确几何信息和相机的丰富纹理信息而成为主流。然而，现有方法多集中于提升位姿估计精度，点云彩色化被视为次要任务。近年来虽有研究联合优化激光雷达和相机位姿以提高映射精度，但仍存在重复彩色化同一区域导致清晰度降低的问题。且当前对彩色点云的评估多依赖定性分析，缺乏全面量化分析。鉴于此，本研究提出 RISED 系统，从投影精度和分布均匀性两方面提升彩色点云质量，并引入新评估指标。

### 二、相关工作
#### (一) RGB 彩色映射
多传感器融合 SLAM 研究众多，旨在提升位姿估计精度与鲁棒性，但点云彩色化常被忽视。近期，PanoVLM、OmniColor 等方法通过联合优化集成色彩与几何信息。R3LIVE++ 使用最大似然估计更新彩色点，但依赖严格时间同步。这些方法多用最新图像彩色化激光雷达帧，导致重复彩色化。在评估方面，虽 R3LIVE++ 和 Miao 等采用光度误差定量评估彩色点云，但多数方法仅进行定性分析，缺乏综合量化分析。本研究利用最优图像彩色化点云，并引入新评估方法。

#### (二) 高斯混合模型（GMM）
GMM 和 GMM - tree 利用期望 - 最大化（EM）算法建模点云。通过 GMM，点到点、点到平面等距离可转化为点到高斯距离。但这些方法固定节点和参数，在平衡粒度与计算复杂度上存在挑战，易过拟合或欠拟合。

### 三、方法论
系统包含两个线程：激光雷达 - IMU 的 SLAM 线程和彩色映射线程。SLAM 线程融合双激光雷达和 IMU 数据，利用直接激光雷达 - 惯性里程计（DLIO）和自定义回环闭合机制估计位姿并生成稠密点云。彩色映射线程包含图像选择和点云致密化两个创新过程，评估方法详见后续部分。

#### (一) 图像选择
当系统进入新区域时，彩色映射线程启动，处理点云帧和图像。为避免模糊，提出投影指标 \( F_i \)，选择投影区域内 \( F_i \) 最小的候选图像作为最佳投影图像。通过点云体素化和平面拟合计算投影指标，小 \( F_i \) 值图像投影面积小，更易被选中。同时引入遮挡检查方法，仅彩色化前景点。

#### (二) 基于动态 GMM 的点云致密化
为消除激光雷达扫描痕迹并提升点云密度与均匀性，提出基于动态 GMM 的点云致密化方法。先用动态增长法将所有点建模为 GMM，再沿最大和第二大的特征向量方向固定步长上采样，生成传感器未直接测量的新点。通过 EM 算法计算后验概率，动态调整 GMM 组件数量以精准拟合几何特征。若组件特征值过小或混合权重低，则移除冗余组件；若组件特征值不稳定且点到函数距离大，则添加组件。

#### (三) 投影与几何评估
传统彩色点云评估仅关注投影精度，本研究提出综合评估向量 \( \eta = [\eta_{\text{tex}} \ \eta_{\text{geo}} \ \eta_{\text{eff}}]^{\top} \)，其范数越小表示彩色点云质量越高。

### 四、实验
#### (一) 实验设置
实验平台包含水平和倾斜激光雷达、全景相机和 IMU，采集涵盖室内外场景的数据集。在六核英特尔 8 代 i7 CPU 和 16 GB RAM 的机载计算机上运行。以 LVI - SAM 和 R3LIVE 为基线方法进行比较。

#### (二) 比较研究
在投影精度上，所提方法的光度误差和有效像素比例优于 LVI - SAM 和 R3LIVE。在结构化区域，所提方法因单视图彩色化整个平面区域而表现优异；在非结构化区域，所提方法同样胜过对比方法。在综合评估向量 \( \eta \) 的各指标上，所提方法在几何精度上表现最佳，且以更少点数实现更高空间完整性，映射效率突出。

#### (三) 消融研究
消融实验显示，图像选择显著降低光度误差，提升点云清晰度；点云致密化提高有效像素比例，增强密度与均匀性。

### 五、结论
本研究提出 RISED 系统，通过图像选择和点云致密化生成纹理清晰的精确点云，并引入综合评估彩色点云精度与效率的新方法。实验表明，所提方法在投影精度、几何精度和映射效率上均优于传统方法，分别提升 55.2%、63.1% 和 30.8%。


## 其他相关知识：

**Indoor Novel View Synthesis**

翻译：室内新视角合成

领域解释：在三维重建和计算机视觉中，指通过已有视角的室内场景数据（如图像、点云等），生成该场景在任意新视角下的逼真图像。常用于虚拟现实、机器人导航等领域。

技术背景：近年来基于神经辐射场（NeRF）的方法在此任务中表现突出，但室内场景因遮挡、复杂光照和弱纹理区域（如白墙）更具挑战性。

**Rendered Image**

翻译：渲染图像

领域解释：指通过三维模型、材质、光照等参数，经图形学算法生成的二维图像。在三维重建中，渲染图像常用于验证重建质量或作为训练数据。

**Surface Normal**

翻译：表面法线

领域解释：描述三维几何表面某点垂直于该平面的方向向量，通常用于光照计算、几何重建和形状分析。在深度学习中，法线图（Normal Map）可作为输入或监督信号。


**结构化环境（Structured Environment）**

定义：
具有明确规则、几何约束和可预测布局的环境。物体的位置、形状和运动模式遵循特定规律，通常由人工设计或高度组织化。

特点：

几何规则性：如室内房间（直线墙壁、直角门框）、工厂流水线（固定设备布局）。

可预测性：物体位置和交互方式已知（例如仓库中的货架排列）。

低动态性：环境变化较少（如办公室的静态家具）。

**非结构化环境（Unstructured Environment）**

定义：
缺乏明确规则或几何约束的环境，物体分布杂乱且动态变化，难以用固定模型描述。

特点：

几何复杂性：如自然地形（崎岖山地）、灾害现场（倒塌建筑碎片）。

不可预测性：物体位置和交互随机（如公共场所的行人移动）。

高动态性：环境频繁变化（如交通路口的车辆流动）。

**GMM**

假设数据是由多个高斯分布（正态分布）叠加而成，每个高斯分布代表数据空间中的一个潜在类别或簇。这种混合模型能够刻画非线性、非凸的数据分布.


